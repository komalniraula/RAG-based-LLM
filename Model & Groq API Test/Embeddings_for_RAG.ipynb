{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB-J1JkuWISa",
        "outputId": "5b28f155-c5fa-44ab-fd9d-d7136a904b66"
      },
      "id": "EB-J1JkuWISa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c498d45-bf23-4f1c-855b-302851444af8",
      "metadata": {
        "id": "4c498d45-bf23-4f1c-855b-302851444af8"
      },
      "outputs": [],
      "source": [
        "# run_query.py\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cf95ed-a348-4d04-84b0-72446e544139",
      "metadata": {
        "id": "64cf95ed-a348-4d04-84b0-72446e544139"
      },
      "outputs": [],
      "source": [
        "# Function to embed queries\n",
        "def embed_query(query, tokenizer, model):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d79bc74-7ead-440c-bf0e-0780661a4c8e",
      "metadata": {
        "id": "2d79bc74-7ead-440c-bf0e-0780661a4c8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fb69fe-c8b6-454a-d73b-40a3e7a58263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix shape: (331, 1024)\n",
            "Splits loaded from disk.\n"
          ]
        }
      ],
      "source": [
        "# Load embeddings from disk\n",
        "embedding_matrix = np.load('embeddings.npy')\n",
        "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n",
        "\n",
        "# Load chunks from disk\n",
        "with open('chunks.npy', 'rb') as f:\n",
        "    splits = np.load(f, allow_pickle=True)\n",
        "print(\"Splits loaded from disk.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ada7df-79c3-4547-a7ac-40e845064d91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ada7df-79c3-4547-a7ac-40e845064d91",
        "outputId": "0f21f49b-b57a-48db-83ca-6dfd6541c5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NewModel(\n",
              "  (embeddings): NewEmbeddings(\n",
              "    (word_embeddings): Embedding(30528, 1024, padding_idx=0)\n",
              "    (rotary_emb): NTKScalingRotaryEmbedding()\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): NewEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-23): 24 x NewLayer(\n",
              "        (attention): NewSdpaAttention(\n",
              "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (o_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (mlp): NewGatedMLP(\n",
              "          (up_gate_proj): Linear(in_features=1024, out_features=8192, bias=False)\n",
              "          (down_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act_fn): GELUActivation()\n",
              "          (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "        (mlp_ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "        (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define the directory where the model and tokenizer are saved\n",
        "load_directory = \"./saved_embedding_model\"\n",
        "\n",
        "# Load the tokenizer from the same directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(load_directory, trust_remote_code=True)\n",
        "\n",
        "# Load the model from the same directory\n",
        "model = AutoModel.from_pretrained(load_directory, trust_remote_code=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72806009-826b-41ac-9d72-b188fb01c61d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72806009-826b-41ac-9d72-b188fb01c61d",
        "outputId": "c525167c-0fe5-4a02-959b-28643d30568d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faiss index loaded from disk.\n"
          ]
        }
      ],
      "source": [
        "# Load the Faiss index\n",
        "index = faiss.read_index('faiss_index.index')\n",
        "print(\"Faiss index loaded from disk.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d17d97-49ad-4c47-a742-8d1f63a93a61",
      "metadata": {
        "id": "b4d17d97-49ad-4c47-a742-8d1f63a93a61"
      },
      "outputs": [],
      "source": [
        "# Function to search the index\n",
        "def search_index(query, tokenizer, model, index, splits, top_k=5):\n",
        "    query_embedding = embed_query(query, tokenizer, model)\n",
        "    query_embedding = np.expand_dims(query_embedding, axis=0).astype('float32')  # Faiss expects a 2D array of float32\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    return [splits[idx] for idx in indices[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3871a0cc-9e5e-4ca2-8278-c54951dab5cc",
      "metadata": {
        "id": "3871a0cc-9e5e-4ca2-8278-c54951dab5cc"
      },
      "outputs": [],
      "source": [
        "# Example query\n",
        "query = \"What is the procedure for opening minor account?\"\n",
        "results = search_index(query, tokenizer, model, index, splits)\n",
        "\n",
        "# Join the results into a single string\n",
        "context = \"\\n\".join(results)\n",
        "\n",
        "# Create the formatted string\n",
        "formatted_string = f\"Question: {query}\\n\\nContext: {context}\"\n",
        "\n",
        "# Print the formatted string\n",
        "#print(formatted_string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY'] = ' ' #Groq API Key"
      ],
      "metadata": {
        "id": "A6vih77jZT_Q"
      },
      "id": "A6vih77jZT_Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da4d542-a1c5-4b49-b2c0-ea368cc7822a",
      "metadata": {
        "id": "9da4d542-a1c5-4b49-b2c0-ea368cc7822a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef17196-9fb5-4dfd-c25c-2c8c822efc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To open a minor account, the following procedure should be followed:\n",
            "\n",
            "1. Remarks \"Minor Account\" should be mentioned on the account opening form and signature specimen card, and on the system during uploading specimen signature.\n",
            "2. Based on the date of birth mentioned on the birth certificate, the date when the minor becomes major must be clearly noted on both the account opening form and specimen signature card as \"Minority concludes on…………… (dd/mm/yy)\".\n",
            "3. The account should be opened and operated by the guardian/legal guardian till the minor becomes major.\n",
            "4. A passport size photo of the account holder (minor) is required.\n",
            "5. On majority, the account holder is entitled to operate the account as a regular account instead of a minor account. A written request of the account holder and guardian should be obtained to change the mode of account operation/account closure.\n",
            "6. Identification documents along with a new account opening form of the account holder should be obtained and updated in the account opening file.\n",
            "7. If the minor account is opened in the bank's standard product for minor accounts (e.g., \"Jyoti Bal Bachat Khata\"), the account should be changed to another account type through an account scheme change. In this case, a new account opening form should be obtained from the account holder.\n",
            "8. Bank staff should upload new specimen signature on the core banking system and remove the remarks \"Minor\". Account status should be changed from \"block\" to active, and all blocked services should be activated.\n",
            "\n",
            "Additionally, the following documents are required for opening a minor account:\n",
            "\n",
            "* Birth certificate issued by the government body and a photo of the minor\n",
            "* Citizenship and photo of the parents/guardian\n",
            "* A recommendation letter from Ward Office/Gaupalika/Municipality (for guardians other than those in the priority list stated in the Muliki Dewani Samhita act 2074)\n",
            "* KYC of both the minor and the guardian/legal guardian\n",
            "\n",
            "When the minor turns 18 years old and becomes major, the account should be blocked for transactions and the account holder is free to operate the account as a regular account.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": formatted_string,\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjpFlb7QePSa"
      },
      "id": "qjpFlb7QePSa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}